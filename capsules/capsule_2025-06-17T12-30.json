{
  "context": "Here is an activity summary of the user's session:\n- [2025-06-17T12:30:00.860258] Opened `activity_log.jsonl - AUTOGEN - Visual Studio Code` using `Code.exe`\n- [2025-06-17T12:30:05.862403] Opened `MCP_A2A - PowerPoint` using `POWERPNT.EXE`\n- [2025-06-17T12:30:15.866593] Opened `activity_log.jsonl - AUTOGEN - Visual Studio Code` using `Code.exe`\n- [2025-06-17T12:30:20.869491] Opened `SPEECH - Word` using `WINWORD.EXE`\n- [2025-06-17T12:30:25.871053] Opened `activity_log.jsonl - AUTOGEN - Visual Studio Code` using `Code.exe`\n\n\n--- MCP_A2A.pptx ---\nMODEL CONTEXT PROTOCOL \u000b&\u000b GOOGLE A2A\u000b(WEEK 1)\nVARUN DAGA (IN) (Manager, Advisory)\n\nSIDDHARTH M(IN) (Intern, Advisory)\nTrained on vast amounts of general knowledge\nSTRENGTHS AND CURRENT USE CASES OF LLMS\nLIMITATIONS OF LLMS IN BUSINESS CONTEXTS\nCURRENT LIMITATIONS\nNEED FOR INTEGRATION\nOVERCOMING LLM SHORTCOMINGS USING AUGMENTATION (RAG)\nCHALLENGES IN PROVIDING CONTEXT AND INTEGRATION\nEvery API required custom integration logic.\nNo unified format for LLMs to   call tools or interpret responses\nLLMS lacked mechanisms to discover and understand available tools.\nLLMS lacked the ability to autonomously choose actions.\nScattered tools outputs, user prompts and intermediate reasoning.\nStateless agents.\nEvery integration was a one-off project.\nManual building of prompt templates and code integration.\nStandardises interfacing with external tools and data sources.\nMCP provides structured, semantically rich business data for grounding LLMs\nEliminates custom integrations between AI models and different systems.\nAids quicker development\nEnable automated  and structured integration of context\nDynamic discovery and utilization of available tools and resources,\nPre-MCP approach\nPost-MCP approach\nComponents of MCP\nCUSTOMER VALUE PROPOSITION\n\n\n\n\n\n\n\n\nMCP connects siloed HR tools into a unified backend for easier employee management.\nFinance teams can use MCP to centralize financial data ingestion, automate forecasting, and optimize cloud spend through AI agents.\nEnterprises use MCP to centralize policy enforcement, automate audit logging across multiple systems.\n\nMCP\u2019s granular activity logs and version control make it easy to trace AI-generated outputs back to their data sources\nMCP-powered chatbots\u00a0can automate common support tasks by integrating with CRMs and other support platforms. \nHospitals can use MCP-powered systems to stream patient data into AI Agents that can autonomously schedule appointments and retrieve diagnostic data.\nAllows developers to build once and connect to many data sources\nBusinesses use MCP to build agentic frameworks where AI systems pull context from various enterprise systems and leveraging tools and APIs as needed.\nConnecting Disparate Systems and Resources\nEnable Real-Time, Context-Aware AI Agents\nAutomate Compliance, Governance, and Audit\nAccelerating Integration\nAnd Support Agentic Workflows\nEnables multiple specialized agents to work together in a coordinated flow.\nEach agents can focus on a specific task, creating a powerful multi-agent system.\nDevelopers can use YAML-based configuration to define workflows, goals, tools, and agents. \nSimplifies development\nScripted multi-agent workflow, where each agent can call tools independently for its own unique role.\nDynamic discovery and utilization of available tools and resources,\nThe client and remote agents communicate through the A2A protocol.\nEach remote agents comprises LLMs and their associated tools which are accessed through MCP.\nBUSINESS VALUE PROPOSITION\n\n\n\n\n\n\n\n\nOver 50 leading tech partners have adopted A2A allowing AI agents to exchange information across platforms.\nA2A  connects AI agents across different departments and cloud environments, breaking down traditional silos and enabling unified workflows.\nOrganizations can build flexible, modular AI ecosystems where specialized agents can be added, upgraded, or replaced\n\nThis allows organizations to rapidly deploy new agents, with minimal integration costs.\nAI agents where first-line support bots handle general inquiries and escalate specialized issues to expert agents.\u00a0\nAgents can also hand off cases across time zones to collaborate with human representatives as needed.\nCustomer support, recommendation  and delivery agents can coordinate to provide instant, personalized order fulfillment, and multilingual support.\nImproved customer satisfaction and reduced operational costs.\nVendor-Agnostic Workflows\nCustomer Service Automation\nModular AI Infrastructure\nRetail and E-Commerce\nMCP and A2A are not competing, but complementary protocols.\nMCP enables tool-level integration, while A2A enables multi-agent collaboration.\nWhile MCP enables communication with tools, A2A can manage coordination and task distribution among agents.\nTogether, they form the backbone of modular, pluggable, AI systems.\nA2A agents will be able to reason, plan, and negotiate across tools registered via MCP..\nThis enables the development of self-improving agent systems.\nMCP and A2A driven systems can lowers the barrier to entry for integrating AI into enterprise workflows.\nSets the stage for non-technical teams to participate in the AI integration process.\nCONTROL FLOW FOR OUR MOCK MCP SERVER PROJECT\nCHALLENGES WITH LARGE CONTEXTS AND STRUCTURED DATA\nCURRENT LIMITATIONS\nPROPOSED SOLUTION\nWorks across industries, including finance, supply chain, HR, policy, compliance\nEnables natural interaction with complex systems \u2014 no query language needed\nCombines memory, reasoning, and explainability\nArchitecture-layer innovation \u2014 extensible to any LLM (e.g., GPT, Claude, LLaMA)\nIdeal foundation for intelligent enterprise copilots and audit-ready agents\n\n--- SPEECH.docx ---\n[Error reading SPEECH.docx]: Package not found at 'SPEECH.docx'\n\n--- activity_logger.py (PY) ---\nimport win32gui\nimport win32process\nimport psutil\nimport time\nimport json\nfrom datetime import datetime\n\nLOG_FILE = \"activity_log.jsonl\"\n\ndef get_active_window_info():\n    try:\n        hwnd = win32gui.GetForegroundWindow()\n        _, pid = win32process.GetWindowThreadProcessId(hwnd)\n        process = psutil.Process(pid)\n        window_title = win32gui.GetWindowText(hwnd)\n        app_name = process.name()\n        return {\n            \"timestamp\": datetime.now().isoformat(),\n            \"app\": app_name,\n            \"title\": window_title\n        }\n    except Exception as e:\n        return {\n            \"timestamp\": datetime.now().isoformat(),\n            \"app\": \"Unknown\",\n            \"title\": f\"Error: {str(e)}\"\n        }\n\ndef log_activity():\n    last_app = None\n    print(\"\ud83d\udfe2 ContextPilot Activity Logger started. Press Ctrl+C to stop.\\n\")\n    while True:\n        info = get_active_window_info()\n        if info[\"app\"] != last_app:  # Log only when app changes\n            print(f\"[{info['timestamp']}] {info['app']} - {info['title']}\")\n            with open(LOG_FILE, \"a\", encoding=\"utf-8\") as f:\n                f.write(json.dumps(info) + \"\\n\")\n            last_app = info[\"app\"]\n        time.sleep(5)  # Check every 5 seconds\n\nif __name__ == \"__main__\":\n    log_activity()\n\n\n--- capsule_builder2.py (PY) ---\nimport os\nimport json\nfrom datetime import datetime\nfrom pathlib import Path\nfrom pptx import Presentation\nimport docx\nimport requests\n\nACTIVITY_LOG_FILE = \"activity_log.jsonl\"\nCAPSULE_DIR = \"capsules\"\nGROQ_API_KEY = \"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\"\nGROQ_API_URL = \"https://api.groq.com/openai/v1/chat/completions\"\nGROQ_MODEL = \"meta-llama/llama-4-scout-17b-16e-instruct\"\n\nPath(CAPSULE_DIR).mkdir(exist_ok=True)\n\ndef load_activity_log():\n    activities = []\n    if os.path.exists(ACTIVITY_LOG_FILE):\n        with open(ACTIVITY_LOG_FILE, \"r\", encoding=\"utf-8\") as f:\n            for line in f:\n                try:\n                    entry = json.loads(line.strip())\n                    if entry.get(\"app\") and entry.get(\"title\"):\n                        activities.append(entry)\n                except json.JSONDecodeError:\n                    continue\n    return activities\n\ndef extract_code_files():\n    code_files = []\n    for file in os.listdir(\".\"):\n        if file.endswith(\".py\"):\n            with open(file, \"r\", encoding=\"utf-8\") as f:\n                code = f.read()\n                code_files.append(f\"--- {file} (PY) ---\\n{code}\")\n    return \"\\n\\n\".join(code_files)\n\ndef extract_word_content(filename):\n    try:\n        doc = docx.Document(filename)\n        return \"\\n\".join([para.text for para in doc.paragraphs if para.text.strip()])\n    except Exception as e:\n        return f\"[Error reading {filename}]: {str(e)}\"\n\ndef extract_ppt_content(filename):\n    try:\n        prs = Presentation(filename)\n        text_runs = []\n        for slide in prs.slides:\n            for shape in slide.shapes:\n                if hasattr(shape, \"text\"):\n                    text_runs.append(shape.text.strip())\n        return \"\\n\".join(text_runs)\n    except Exception as e:\n        return f\"[Error reading {filename}]: {str(e)}\"\n\ndef summarize_context(context_text):\n    headers = {\n        \"Content-Type\": \"application/json\",\n        \"Authorization\": f\"Bearer {GROQ_API_KEY}\"\n    }\n\n    system_prompt = (\n        \"You are a summarization assistant. Read the session context below and summarize the user's goals and actions in 3 sentences.\"\n    )\n\n    messages = [\n        {\"role\": \"system\", \"content\": system_prompt},\n        {\"role\": \"user\", \"content\": context_text}\n    ]\n\n    response = requests.post(GROQ_API_URL, headers=headers, json={\"model\": GROQ_MODEL, \"messages\": messages})\n    if response.status_code == 200:\n        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n    else:\n        return f\"[Groq API error {response.status_code}]: {response.text}\"\n\ndef save_capsule(context, summary):\n    timestamp = datetime.now().strftime(\"%Y-%m-%dT%H-%M\")\n    capsule_path = Path(CAPSULE_DIR) / f\"capsule_{timestamp}.json\"\n    with open(capsule_path, \"w\", encoding=\"utf-8\") as f:\n        json.dump({\"context\": context, \"summary\": summary}, f, indent=2)\n    print(f\"\\n\u2705 Capsule saved: {capsule_path}\")\n\nif __name__ == \"__main__\":\n    print(\"\ud83e\udde0 Building new capsule with Word + PPT + Logs + Code...\\n\")\n\n    # Load activities\n    activities = load_activity_log()\n    activity_summary = \"\"\n    file_contexts = []\n\n    for entry in activities:\n        app = entry[\"app\"]\n        title = entry[\"title\"]\n        activity_summary += f\"- [{entry['timestamp']}] Opened `{title}` using `{app}`\\n\"\n\n        # Parse Word file if title matches\n        if \"Word\" in title and \"SPEECH\" in title:\n            file_contexts.append(f\"--- SPEECH.docx ---\\n{extract_word_content('SPEECH.docx')}\")\n        elif \"PowerPoint\" in title and \"MCP_A2A\" in title:\n            file_contexts.append(f\"--- MCP_A2A.pptx ---\\n{extract_ppt_content('MCP_A2A.pptx')}\")\n\n    # Add code files\n    code_block = extract_code_files()\n    full_context = f\"Here is an activity summary of the user's session:\\n{activity_summary}\\n\\n\" + \"\\n\\n\".join(file_contexts) + \"\\n\\n\" + code_block\n\n    # Summarize + Save\n    print(\"\ud83d\udcdd Summary:\")\n    summary = summarize_context(full_context)\n    print(\"\", summary)\n    save_capsule(full_context, summary)\n\n\n--- resume_session_groq.py (PY) ---\nimport json\nimport requests\nfrom datetime import datetime\nfrom pathlib import Path\n\nCAPSULE_DIR = \"capsules\"\nLATEST_CAPSULE = sorted(Path(CAPSULE_DIR).glob(\"capsule_*.json\"))[-1]\n\nGROQ_API_KEY = \"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\"\nGROQ_API_URL = \"https://api.groq.com/openai/v1/chat/completions\"\nGROQ_MODEL = \"meta-llama/llama-4-scout-17b-16e-instruct\"\n\ndef load_latest_capsule():\n    with open(LATEST_CAPSULE, \"r\", encoding=\"utf-8\") as f:\n        return json.load(f)\n\ndef query_groq_model(context_text, user_question):\n    headers = {\n        \"Content-Type\": \"application/json\",\n        \"Authorization\": f\"Bearer {GROQ_API_KEY}\",\n    }\n\n    prompt = f\"\"\"You are a workplace assistant.\n\nHere is the session context:\n{context_text}\n\nNow answer this question from the user:\n{user_question}\n\"\"\"\n\n    data = {\n        \"model\": GROQ_MODEL,\n        \"messages\": [\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n    }\n\n    response = requests.post(GROQ_API_URL, headers=headers, json=data)\n    if response.status_code == 200:\n        content = response.json()\n        print(\"\\n\ud83e\udd16 Assistant Response:\")\n        print(content[\"choices\"][0][\"message\"][\"content\"])\n    else:\n        print(f\"\u274c Error {response.status_code}: {response.text}\")\n\nif __name__ == \"__main__\":\n    print(\"\ud83d\udd01 Resuming last context capsule...\\n\")\n\n    capsule = load_latest_capsule()\n    print(f\"\ud83d\udcc2 Loaded capsule from: {LATEST_CAPSULE}\")\n    print(f\"\\n\ud83e\udde0 Capsule Summary:\\n{capsule.get('summary', '(No summary)')}\\n\")\n    print(f\"\ud83d\udcc4 Context Size: {len(capsule.get('context', '')) // 4} tokens (approx.)\\n\")\n\n    question = input(\"> What would you like to ask the assistant about this session?\\n> \").strip()\n    if question:\n        query_groq_model(capsule[\"context\"], question)\n\n\n--- streamlit_capsule_app.py (PY) ---\nimport streamlit as st\nimport json\nimport requests\nfrom pathlib import Path\n\n# Constants\nCAPSULE_DIR = \"capsules\"\nGROQ_API_KEY = \"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\"\nGROQ_API_URL = \"https://api.groq.com/openai/v1/chat/completions\"\nGROQ_MODEL = \"meta-llama/llama-4-scout-17b-16e-instruct\"\n\n# Load latest capsule file\ndef load_latest_capsule():\n    capsules = sorted(Path(CAPSULE_DIR).glob(\"capsule_*.json\"))\n    if not capsules:\n        return None, None\n    latest = capsules[-1]\n    with open(latest, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return data, latest.name\n\n# Send query to Groq model\ndef query_groq_model(context_text, user_question):\n    headers = {\n        \"Content-Type\": \"application/json\",\n        \"Authorization\": f\"Bearer {GROQ_API_KEY}\"\n    }\n    prompt = f\"\"\"You are a workplace assistant.\n\nHere is the session context:\n{context_text}\n\nNow answer this question from the user:\n{user_question}\n\"\"\"\n    data = {\n        \"model\": GROQ_MODEL,\n        \"messages\": [\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n    }\n    response = requests.post(GROQ_API_URL, headers=headers, json=data)\n    if response.status_code == 200:\n        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n    else:\n        return f\" Error {response.status_code}: {response.text}\"\n\n# Streamlit UI\nst.set_page_config(page_title=\"ContextPilot QA\", layout=\"wide\")\nst.title(\"ContextPilot: Capsule Query App\")\n\ncapsule, capsule_name = load_latest_capsule()\nif capsule is None:\n    st.warning(\"No capsule found in the 'capsules' directory.\")\n    st.stop()\n\nwith st.expander(\"Capsule Summary\"):\n    st.markdown(f\"**Filename:** `{capsule_name}`\")\n    st.markdown(f\"**Summary:**\\n{capsule.get('summary', '(No summary)')}\")\n    st.markdown(f\"**Context Size:** `{len(capsule.get('context', '')) // 4}` tokens (approx.)\")\n\nst.divider()\n\nquestion = st.text_input(\"Ask a question about your last session:\", placeholder=\"e.g., What were the limitations of LLMs I noted?\")\nif st.button(\"\ud83d\udd0d Submit Query\") and question.strip():\n    with st.spinner(\"Querying Groq...\"):\n        response = query_groq_model(capsule[\"context\"], question.strip())\n        st.success(\"Response received:\")\n        st.markdown(response)\n\n",
  "summary": "Here is a 3 sentence summary of the user's goals and actions:\n\nThe user aims to create an activity summary and context capsule using various files, including a PowerPoint presentation, a Word document, and activity logs. The user's actions involve loading activity logs, extracting content from files, and summarizing the context using the Groq API. The user also intends to build a capsule that can be used to query a Groq model and retrieve answers to questions about their session."
}